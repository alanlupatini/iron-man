{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62c67f1-72e7-4fa3-9cf8-29acc10e7e7f",
   "metadata": {},
   "source": [
    "## Initial Merge of raw databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58e1d65-71ca-4c58-a729-15c39872abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved as CSV: ..\\data\\raw\\merged_ironman_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = r'..\\data\\raw'\n",
    "file1 = os.path.join(folder_path, 'or1.xlsx')\n",
    "file2 = os.path.join(folder_path, 'or2.xlsx')\n",
    "\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "output_path_csv = os.path.join(folder_path, 'merged_ironman_data.csv')\n",
    "merged_df.to_csv(output_path_csv, index=False)\n",
    "\n",
    "print(f\"Success! Saved as CSV: {output_path_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd77d4-06b2-427b-b3a7-39be8dc2897b",
   "metadata": {},
   "source": [
    "## First data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58d2211-f9e2-4b5a-8e18-feb71efab2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country', 'Invoice', 'Price', 'Customer ID']\n",
      "\n",
      "Missing Values per Column:\n",
      "InvoiceNo      525461\n",
      "StockCode           0\n",
      "Description      4382\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice      525461\n",
      "CustomerID     660541\n",
      "Country             0\n",
      "Invoice        541909\n",
      "Price          541909\n",
      "Customer ID    649836\n",
      "dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "        InvoiceNo StockCode                         Description      Quantity  \\\n",
      "count    541909.0   1067370                             1062988  1.067370e+06   \n",
      "unique    25900.0      5305                                5698           NaN   \n",
      "top      573585.0    85123A  WHITE HANGING HEART T-LIGHT HOLDER           NaN   \n",
      "freq       1114.0      5829                                5918           NaN   \n",
      "mean          NaN       NaN                                 NaN  9.938907e+00   \n",
      "min           NaN       NaN                                 NaN -8.099500e+04   \n",
      "25%           NaN       NaN                                 NaN  1.000000e+00   \n",
      "50%           NaN       NaN                                 NaN  3.000000e+00   \n",
      "75%           NaN       NaN                                 NaN  1.000000e+01   \n",
      "max           NaN       NaN                                 NaN  8.099500e+04   \n",
      "std           NaN       NaN                                 NaN  1.727059e+02   \n",
      "\n",
      "                          InvoiceDate      UnitPrice     CustomerID  \\\n",
      "count                         1067370  541909.000000  406829.000000   \n",
      "unique                            NaN            NaN            NaN   \n",
      "top                               NaN            NaN            NaN   \n",
      "freq                              NaN            NaN            NaN   \n",
      "mean    2011-01-02 21:13:27.819556096       4.611114   15287.690570   \n",
      "min               2009-12-01 07:45:00  -11062.060000   12346.000000   \n",
      "25%               2010-07-09 09:46:00       1.250000   13953.000000   \n",
      "50%               2010-12-07 15:28:00       2.080000   15152.000000   \n",
      "75%               2011-07-22 10:23:00       4.130000   16791.000000   \n",
      "max               2011-12-09 12:50:00   38970.000000   18287.000000   \n",
      "std                               NaN      96.759853    1713.600303   \n",
      "\n",
      "               Country   Invoice          Price    Customer ID  \n",
      "count          1067370  525461.0  525461.000000  417534.000000  \n",
      "unique              43   28816.0            NaN            NaN  \n",
      "top     United Kingdom  537434.0            NaN            NaN  \n",
      "freq            981330     675.0            NaN            NaN  \n",
      "mean               NaN       NaN       4.688834   15360.645478  \n",
      "min                NaN       NaN  -53594.360000   12346.000000  \n",
      "25%                NaN       NaN       1.250000   13983.000000  \n",
      "50%                NaN       NaN       2.100000   15311.000000  \n",
      "75%                NaN       NaN       4.210000   16799.000000  \n",
      "max                NaN       NaN   25111.090000   18287.000000  \n",
      "std                NaN       NaN     146.126914    1680.811316  \n"
     ]
    }
   ],
   "source": [
    "print(\"Column Names:\", merged_df.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(merged_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27d4b8-0c3b-4390-bdbe-0e80b66c7d78",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e16121-77da-4499-9161-265ed066571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['InvoiceNo'] = merged_df['InvoiceNo'].fillna(merged_df['Invoice'])\n",
    "merged_df['UnitPrice'] = merged_df['UnitPrice'].fillna(merged_df['Price'])\n",
    "merged_df['CustomerID'] = merged_df['CustomerID'].fillna(merged_df['Customer ID'])\n",
    "\n",
    "cols_to_drop = ['Invoice', 'Price', 'Customer ID']\n",
    "merged_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Handle Missing Values\n",
    "merged_df['Description'] = merged_df['Description'].fillna('Unknown')\n",
    "\n",
    "# CustomerID\n",
    "merged_df['CustomerID'] = merged_df['CustomerID'].fillna(0).astype(int)\n",
    "\n",
    "# Data Type Correction\n",
    "merged_df['InvoiceDate'] = pd.to_datetime(merged_df['InvoiceDate'])\n",
    "\n",
    "print(\"Cleaned Data Overview:\")\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bf533-104b-420e-9543-3ecf14ebb1e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d49f11-42b6-4597-ada2-5fe2fa876a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c7ef557-27ca-4e1a-9425-37e2c1b60c58",
   "metadata": {},
   "source": [
    "## Features ready for ML model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651727b4-3056-4ad9-b44c-c61be3cfa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique Customers: {merged_df['CustomerID'].nunique()}\")\n",
    "print(f\"Unique Products: {merged_df['StockCode'].nunique()}\")\n",
    "\n",
    "import numpy as np\n",
    "print(\"\\nAny infinite values?\")\n",
    "print(np.isinf(merged_df.select_dtypes(include=np.number)).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d7603-3733-4fa0-904d-6e4f593b8bb3",
   "metadata": {},
   "source": [
    "## Saving cleaned DF for Project Iron Man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2628b-4083-466f-b98d-f5e78ce99c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Reload the raw merged data\n",
    "\n",
    "# Safe Merge and Type Conversion (Same as before)\n",
    "if 'Invoice' in merged_df.columns:\n",
    "    merged_df['InvoiceNo'] = merged_df['InvoiceNo'].fillna(merged_df['Invoice'])\n",
    "if 'Price' in merged_df.columns:\n",
    "    merged_df['UnitPrice'] = merged_df['UnitPrice'].fillna(merged_df['Price'])\n",
    "if 'Customer ID' in merged_df.columns:\n",
    "    merged_df['CustomerID'] = merged_df['CustomerID'].fillna(merged_df['Customer ID'])\n",
    "\n",
    "merged_df['InvoiceNo'] = merged_df['InvoiceNo'].astype(str)\n",
    "merged_df['CustomerID'] = merged_df['CustomerID'].fillna(0)\n",
    "\n",
    "# THE CHANGE: Smart Filtering\n",
    "cleaned_df = merged_df[merged_df['UnitPrice'] > 0].copy()\n",
    "\n",
    "# Create an 'Is_Return' flag for easier ML processing later\n",
    "cleaned_df['Is_Return'] = cleaned_df['Quantity'] < 0\n",
    "\n",
    "print(\"New Cleaning Results:\")\n",
    "print(f\"Total Transactions: {len(cleaned_df)}\")\n",
    "print(f\"Number of Returns Preserved: {cleaned_df['Is_Return'].sum()}\")\n",
    "\n",
    "# Overwrite your clean parquet file\n",
    "output_path = r'C:\\Users\\ASUS\\Desktop\\courses\\projects\\iron-man\\data\\clean\\ironman.parquet'\n",
    "cleaned_df.to_parquet(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f13a24-26e3-4687-9721-e45b5398a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redoing data cleaning to not remove neg sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323d310-2d36-4b10-a6e1-67cbb2a630d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r'C:\\Users\\ASUS\\Desktop\\courses\\projects\\iron-man\\data\\raw'\n",
    "\n",
    "if 'Invoice' in merged_df.columns:\n",
    "    merged_df['InvoiceNo'] = merged_df['InvoiceNo'].fillna(merged_df['Invoice'])\n",
    "\n",
    "if 'Price' in merged_df.columns:\n",
    "    merged_df['UnitPrice'] = merged_df['UnitPrice'].fillna(merged_df['Price'])\n",
    "\n",
    "if 'Customer ID' in merged_df.columns:\n",
    "    merged_df['CustomerID'] = merged_df['CustomerID'].fillna(merged_df['Customer ID'])\n",
    "\n",
    "cols_to_drop = ['Invoice', 'Price', 'Customer ID']\n",
    "existing_cols_to_drop = [c for c in cols_to_drop if c in merged_df.columns]\n",
    "merged_df.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "\n",
    "merged_df['InvoiceNo'] = merged_df['InvoiceNo'].astype(str)\n",
    "merged_df['StockCode'] = merged_df['StockCode'].astype(str)\n",
    "merged_df['InvoiceDate'] = pd.to_datetime(merged_df['InvoiceDate'])\n",
    "\n",
    "merged_df = merged_df[(merged_df['Quantity'] > 0) & (merged_df['UnitPrice'] > 0)]\n",
    "\n",
    "output_parquet = os.path.join(folder_path, 'ironman2.parquet')\n",
    "merged_df.to_parquet(output_parquet, index=False)\n",
    "\n",
    "print(f\"File cleaned and saved successfully to: {output_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d66ec-c8fc-40f8-9dcb-51264e335ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20cdf6a-b2fc-4c14-b48f-02f70e0e3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# LOAD & FIX THE DATA\n",
    "raw_file = r'C:\\Users\\ASUS\\Desktop\\courses\\projects\\iron-man\\data\\raw\\merged_ironman_data.csv'\n",
    "\n",
    "print(f\"Reading file: {raw_file}...\")\n",
    "# encoding='ISO-8859-1' helps if the CSV has weird currency symbols like Â£\n",
    "df = pd.read_csv(raw_file, encoding='ISO-8859-1')\n",
    "\n",
    "# fill the missing ID\n",
    "df['CustomerID'] = df['CustomerID'].fillna(0)\n",
    "\n",
    "# filter out items with 0 price (junk), BUT i keep negative Quantities (returns)\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "\n",
    "# Calculate TotalPrice\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Save this version so we stop losing returns!\n",
    "clean_path = r'C:\\Users\\ASUS\\Desktop\\courses\\projects\\iron-man\\data\\clean\\ironman2.parquet'\n",
    "df.to_parquet(clean_path, index=False)\n",
    "print(f\"Saved fixed file to: {clean_path}\")\n",
    "\n",
    "# Check if I actually have returns now\n",
    "num_returns = len(df[df['Quantity'] < 0])\n",
    "print(f\"SUCCESS! Found {num_returns} return rows.\")\n",
    "\n",
    "\n",
    "# --- PART 2: THE GRAPH THAT WAS BLANK ---\n",
    "if num_returns > 0:\n",
    "    # Clean descriptions\n",
    "    df['Description'] = df['Description'].astype(str).str.strip()\n",
    "\n",
    "    # Get Sales (Sold)\n",
    "    sales = df[df['Quantity'] > 0].groupby('Description')['Quantity'].sum().reset_index()\n",
    "    sales.columns = ['Description', 'Sold']\n",
    "\n",
    "    #Get Returns\n",
    "    rets = df[df['Quantity'] < 0].copy()\n",
    "    rets['Qty_Abs'] = rets['Quantity'].abs()\n",
    "    returns = rets.groupby('Description')['Qty_Abs'].sum().reset_index()\n",
    "    returns.columns = ['Description', 'Returned']\n",
    "\n",
    "    # merge\n",
    "    stats = pd.merge(sales, returns, on='Description', how='inner')\n",
    "    \n",
    "    # Math time\n",
    "    stats['Return_Prob'] = (stats['Returned'] / stats['Sold']) * 100\n",
    "    \n",
    "    # Filter: Only show items sold > 50 times (to ignore rare stuff)\n",
    "    top_junk = stats[stats['Sold'] > 50].sort_values('Return_Prob', ascending=False).head(10)\n",
    "\n",
    "    # Plot\n",
    "    print(\"\\nGenerating the Headaches Graph...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=top_junk, x='Return_Prob', y='Description', palette='Reds_r')\n",
    "    plt.title('Top 10 Products by Return Probability (Items sold > 50 times)')\n",
    "    plt.xlabel('Return Probability (%)')\n",
    "    plt.show()\n",
    "\n",
    "    # 8. Print the list\n",
    "    print(\"\\nTop risky items:\")\n",
    "    print(top_junk[['Description', 'Sold', 'Returned', 'Return_Prob']])\n",
    "\n",
    "else:\n",
    "    print(\"0 returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb93a03-c432-40f4-b67c-d87ec504149c",
   "metadata": {},
   "source": [
    "## Saving it into a SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e063868-d598-4ce2-9f0a-2b40b38201fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to ironman...\n",
      "Uploading... this may take a moment.\n",
      "Success! Data is now in MySQL.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load credentials\n",
    "load_dotenv()\n",
    "user = os.getenv('DB_USER')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "host = os.getenv('DB_HOST')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "# 2. Load Parquet\n",
    "file_path = r\"C:\\Users\\ASUS\\Desktop\\courses\\projects\\iron-man\\data\\clean\\ironman2.parquet\"\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Direct Connection\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}/{db_name}')\n",
    "\n",
    "print(f\"Connecting to {db_name}...\")\n",
    "\n",
    "try:\n",
    "    # Upload Data\n",
    "    # chunksize helps if the file is large, preventing memory overflows\n",
    "    print(\"Uploading... this may take a moment.\")\n",
    "    df.to_sql('transactions', con=engine, if_exists='replace', index=False, chunksize=1000)\n",
    "    print(\"Success! Data is now in MySQL.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Always close the engine to prevent future locks\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da783770-d9ec-4ac8-ab56-aadd6d02b6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
